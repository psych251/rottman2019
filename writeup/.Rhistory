group_by(Purity_Violation, High_Dosage) %>%
summarize(meanWrongness = (sd(Rating, na.rm=T)))
sd_Harm_LowDosage <- sd[1,3]
sd_Harm_HighDosage <- sd[2,3]
sd_Purity_LowDosage <- sd[3,3]
sd_Purity_HighDosage <- sd[4,3]
# The difference in standard deviations between high-dosage  and low-dosage harm violations, and high-dosage and low-dosage purity violations
sd_Harm_HighDosage - sd_Harm_LowDosage
sd_Purity_HighDosage - sd_Purity_LowDosage
# Hmmmm... I seem to be getting the OPPOSITE results as the authors. Is this an error in my code? Also, I couldn't get the standard deviation, is that an error in my code?
#First analysis, difference of means
# I'm trying to find the difference in the wrongness rating between the high-dosage and the low-dosage versions of the scenarios of the HARM transgressions. Then for the purity transgressions, I'll find the same thing.
# Do I also need to group by prompt?? so each question gets its own analysis?
means <- d %>%
group_by(Purity_Violation, High_Dosage) %>%
summarize(meanWrongness = (mean(Rating, na.rm=T)))
mean_Harm_LowDosage <- means[1,3]
mean_Harm_HighDosage <- means[2,3]
mean_Purity_LowDosage <- means[3,3]
mean_Purity_HighDosage <- means[4,3]
# The difference between high-dosage  and low-dosage harm violations, and high-dosage and low-dosage purity violations
mean_Harm_HighDosage - mean_Harm_LowDosage
mean_Purity_HighDosage - mean_Purity_LowDosage
# Now I'll do the same analysis for standard deviations
sd <- d %>%
group_by(Purity_Violation, High_Dosage) %>%
summarize(meanWrongness = (sd(Rating, na.rm=T)))
sd_Harm_LowDosage <- sd[1,3]
sd_Harm_HighDosage <- sd[2,3]
sd_Purity_LowDosage <- sd[3,3]
sd_Purity_HighDosage <- sd[4,3]
# The difference in standard deviations between high-dosage  and low-dosage harm violations, and high-dosage and low-dosage purity violations
sd_Harm_HighDosage - sd_Harm_LowDosage
sd_Purity_HighDosage - sd_Purity_LowDosage
# Hmmmm... I seem to be getting the OPPOSITE results as the authors. Is this an error in my code? Also, I couldn't get the standard deviation, is that an error in my code?
#First analysis, difference of means
# I'm trying to find the difference in the wrongness rating between the high-dosage and the low-dosage versions of the scenarios of the HARM transgressions. Then for the purity transgressions, I'll find the same thing.
# Do I also need to group by prompt?? so each question gets its own analysis?
means <- d %>%
group_by(Purity_Violation, High_Dosage) %>%
summarize(meanWrongness = (mean(Rating, na.rm=T)))
mean_Harm_LowDosage <- means[1,3]
mean_Harm_HighDosage <- means[2,3]
mean_Purity_LowDosage <- means[3,3]
mean_Purity_HighDosage <- means[4,3]
# The difference between high-dosage  and low-dosage harm violations, and high-dosage and low-dosage purity violations
mean_Harm_HighDosage - mean_Harm_LowDosage
mean_Purity_HighDosage - mean_Purity_LowDosage
# Now I'll do the same analysis for standard deviations
sd <- d %>%
group_by(Purity_Violation, High_Dosage) %>%
summarize(meanWrongness = (sd(Rating, na.rm=T)))
sd_Harm_LowDosage <- sd[1,3]
sd_Harm_HighDosage <- sd[2,3]
sd_Purity_LowDosage <- sd[3,3]
sd_Purity_HighDosage <- sd[4,3]
# The difference in standard deviations between high-dosage  and low-dosage harm violations, and high-dosage and low-dosage purity violations
sd_Harm_HighDosage - sd_Harm_LowDosage
sd_Purity_HighDosage - sd_Purity_LowDosage
# Hmmmm... I seem to be getting the OPPOSITE results as the authors. Is this an error in my code? Also, I couldn't get the standard deviation, is that an error in my code?
# The difference between high-dosage  and low-dosage harm violations, and high-dosage and low-dosage purity violations
mean_Harm_HighDosage - mean_Harm_LowDosage
###Data Preparation
# I created a survey on Qualtrics, and linked that survey to Mechanical Turk. My survey has 16 questions, and each question has two dosages, so it is actually 32 questions total. All questions are provided in the Rottman 2019 paper. Each participant is presented with 16 moral violations, that vary by domain (harm vs. purity violation) and by . dosage (low vs. high or magnitude vs. frequency). I will use the "Randomizer" function in Qualtrics. To ensure that participants see the appropriate questions.
####Load Relevant Libraries and Functions
# The libraries I need are the useful, all-purpose libraries:
library(foreign) # for reading spss formatted data
library(tidyverse)
####Import data, using the workaround Mike sent to the class in order to read Qualtrics data into R
#Also, how do I make sure that my data is anonymized??? I didn't really understand the class instructions for Mturk anonymization
filename <- "PilotAdata.csv"
headers = read_csv(filename, col_names = FALSE, n_max = 1)
df = read_csv(filename, skip = 3, col_names = FALSE)
colnames(df)= headers
#### Inspect data
colnames(df)
#### Data exclusion / filtering
# For Pilot A, I have 6 actual survey results, and the rest are spam from when I was testing/building the survey.
# So I need to get rid of the ~25 entries that are spam. The spam were all short, less than 75 seconds
# I'll also have to filter out the people who failed the attention checks.
# Per Rottman, you fail the attention check if you rate "a person destroys the entire planet" below 49 on the moral
# wrongness scale, or if you rate "a person gives money to a charitable organization" above 51 on moral wrongness.
data <- df %>%
filter(DistributionChannel == "anonymous") %>% # remove all the surveys that were unanswered and were just a "preview," leaving only the surveys that were "anonymous"
filter( (Att1_8 > 49) | (Att2_4 < 51) )  ## Include only rows where the person passed the first attention check, OR where they passed the second attention check.
# Is the above fix okay? Am I keeping all the data I intend to keep? --> I HAVE A PROBLEM HERE!!! It's also filtering out all the people who took Att2 but not Att1. How do I get it to keep the results when Att1_8 = NA?
#Also, I could maybe just get rid of the first row. I think the second filter does the same thing.
#Also, is there a way to keep track of how much data is excluded? I'm planning to go to office hours on Tuesday 12/3 and go through many of these questions.
head(data)
#### Tidy my data
# I have a huge, super wide dataset. How do I make this tidier? What am I even trying to turn it into?
d <- data %>%
pivot_longer(cols = A1_10:Att2_4, names_to = "Prompt", values_to = "Rating") %>% # pivots into long form
select(c("Prompt", "Rating")) %>% # keeps only the columns I need
mutate(Purity_Violation = grepl("2", x = Prompt)) %>% # adds a column that says "TRUE" if the violation is a purity violation and "FALSE" if the violation is a harm violation
mutate(High_Dosage = grepl("'", x = Prompt)) # adds a column that says "TRUE" if the violation is the high-dosage version violation and "FALSE" if the violation is the low-dosage version violation
colnames(d)
# Now I only have four columns! Hurray! My data is nice and clean and long.
## Do I need to clean this up and label by subject?? I lost a lot of information when I tidied my data
# Do I need to add a dosage type (magnitude v frequence). ?? I think? although I think they don't end up using the dosage TYPE at all in the analysis.
# I should probably get rid of a lot of columns I don't need... do I need to do this?
#First analysis, difference of means
# I'm trying to find the difference in the wrongness rating between the high-dosage and the low-dosage versions of the scenarios of the HARM transgressions. Then for the purity transgressions, I'll find the same thing.
# Do I also need to group by prompt?? so each question gets its own analysis?
means <- d %>%
group_by(Purity_Violation, High_Dosage) %>%
summarize(meanWrongness = (mean(Rating, na.rm=T)))
mean_Harm_LowDosage <- means[1,3]
mean_Harm_HighDosage <- means[2,3]
mean_Purity_LowDosage <- means[3,3]
mean_Purity_HighDosage <- means[4,3]
# The difference between high-dosage  and low-dosage harm violations, and high-dosage and low-dosage purity violations
mean_Harm_HighDosage - mean_Harm_LowDosage
mean_Purity_HighDosage - mean_Purity_LowDosage
# Now I'll do the same analysis for standard deviations
sd <- d %>%
group_by(Purity_Violation, High_Dosage) %>%
summarize(meanWrongness = (sd(Rating, na.rm=T)))
sd_Harm_LowDosage <- sd[1,3]
sd_Harm_HighDosage <- sd[2,3]
sd_Purity_LowDosage <- sd[3,3]
sd_Purity_HighDosage <- sd[4,3]
# The difference in standard deviations between high-dosage  and low-dosage harm violations, and high-dosage and low-dosage purity violations
sd_Harm_HighDosage - sd_Harm_LowDosage
sd_Purity_HighDosage - sd_Purity_LowDosage
# Hmmmm... I seem to be getting the OPPOSITE results as the authors. Is this an error in my code? Also, I couldn't get the standard deviation, is that an error in my code?
# Library
library(ggplot2)
View(d)
p <- ggplot(d, aes(x=name, y=Rating, fill=name)) + # fill=name allow to automatically dedicate a color for each group
geom_violin()
p
p <- ggplot(d, aes(x=name, y=Rating, fill=name)) + # fill=name allow to automatically dedicate a color for each group
geom_violin()
ggplot(d, aes(x=name, y=Rating, fill=name)) + # fill=name allow to automatically dedicate a color for each group
geom_violin()
p <- ggplot(d, aes(x=name, y=Rating)) + # fill=name allow to automatically dedicate a color for each group
geom_violin()
ggplot(d, aes(x=name, y=Rating)) + # fill=name allow to automatically dedicate a color for each group
geom_violin()
p <- ggplot(d, aes(x=name, y=Rating, fill=name)) +
geom_violin()
p
# Most basic violin chart
ggplot(d, aes(x=name, y=Rating)) +
geom_violin()
# Most basic violin chart
ggplot(d, aes(x=Purity_Violation, y=Rating, fill=name)) +
geom_violin()
###Data Preparation
# I created a survey on Qualtrics, and linked that survey to Mechanical Turk. My survey has 16 questions, and each question has two dosages, so it is actually 32 questions total. All questions are provided in the Rottman 2019 paper. Each participant is presented with 16 moral violations, that vary by domain (harm vs. purity violation) and by . dosage (low vs. high or magnitude vs. frequency). I will use the "Randomizer" function in Qualtrics. To ensure that participants see the appropriate questions.
####Load Relevant Libraries and Functions
# The libraries I need are the useful, all-purpose libraries:
library(foreign) # for reading spss formatted data
library(tidyverse)
####Import data, using the workaround Mike sent to the class in order to read Qualtrics data into R
#Also, how do I make sure that my data is anonymized??? I didn't really understand the class instructions for Mturk anonymization
filename <- "PilotAdata.csv"
headers = read_csv(filename, col_names = FALSE, n_max = 1)
df = read_csv(filename, skip = 3, col_names = FALSE)
colnames(df)= headers
#### Inspect data
colnames(df)
#### Data exclusion / filtering
# For Pilot A, I have 6 actual survey results, and the rest are spam from when I was testing/building the survey.
# So I need to get rid of the ~25 entries that are spam. The spam were all short, less than 75 seconds
# I'll also have to filter out the people who failed the attention checks.
# Per Rottman, you fail the attention check if you rate "a person destroys the entire planet" below 49 on the moral
# wrongness scale, or if you rate "a person gives money to a charitable organization" above 51 on moral wrongness.
data <- df %>%
filter(DistributionChannel == "anonymous") %>% # remove all the surveys that were unanswered and were just a "preview," leaving only the surveys that were "anonymous"
filter( (Att1_8 > 49) | (Att2_4 < 51) )  ## Include only rows where the person passed the first attention check, OR where they passed the second attention check.
# Is the above fix okay? Am I keeping all the data I intend to keep? --> I HAVE A PROBLEM HERE!!! It's also filtering out all the people who took Att2 but not Att1. How do I get it to keep the results when Att1_8 = NA?
#Also, I could maybe just get rid of the first row. I think the second filter does the same thing.
#Also, is there a way to keep track of how much data is excluded? I'm planning to go to office hours on Tuesday 12/3 and go through many of these questions.
head(data)
#### Tidy my data
# I have a huge, super wide dataset. How do I make this tidier? What am I even trying to turn it into?
d <- data %>%
pivot_longer(cols = A1_10:Att2_4, names_to = "Prompt", values_to = "Rating") %>% # pivots into long form
select(c("Prompt", "Rating")) %>% # keeps only the columns I need
mutate(Purity_Violation = grepl("2", x = Prompt)) %>% # adds a column that says "TRUE" if the violation is a purity violation and "FALSE" if the violation is a harm violation
mutate(High_Dosage = grepl("'", x = Prompt)) # adds a column that says "TRUE" if the violation is the high-dosage version violation and "FALSE" if the violation is the low-dosage version violation
colnames(d)
# Now I only have four columns! Hurray! My data is nice and clean and long.
## Do I need to clean this up and label by subject?? I lost a lot of information when I tidied my data
# Do I need to add a dosage type (magnitude v frequence). ?? I think? although I think they don't end up using the dosage TYPE at all in the analysis.
# I should probably get rid of a lot of columns I don't need... do I need to do this?
#First analysis, difference of means
# I'm trying to find the difference in the wrongness rating between the high-dosage and the low-dosage versions of the scenarios of the HARM transgressions. Then for the purity transgressions, I'll find the same thing.
# Do I also need to group by prompt?? so each question gets its own analysis?
means <- d %>%
group_by(Purity_Violation, High_Dosage) %>%
summarize(meanWrongness = (mean(Rating, na.rm=T)))
mean_Harm_LowDosage <- means[1,3]
mean_Harm_HighDosage <- means[2,3]
mean_Purity_LowDosage <- means[3,3]
mean_Purity_HighDosage <- means[4,3]
# The difference between high-dosage  and low-dosage harm violations, and high-dosage and low-dosage purity violations
mean_Harm_HighDosage - mean_Harm_LowDosage
mean_Purity_HighDosage - mean_Purity_LowDosage
# Now I'll do the same analysis for standard deviations
sd <- d %>%
group_by(Purity_Violation, High_Dosage) %>%
summarize(meanWrongness = (sd(Rating, na.rm=T)))
sd_Harm_LowDosage <- sd[1,3]
sd_Harm_HighDosage <- sd[2,3]
sd_Purity_LowDosage <- sd[3,3]
sd_Purity_HighDosage <- sd[4,3]
# The difference in standard deviations between high-dosage  and low-dosage harm violations, and high-dosage and low-dosage purity violations
sd_Harm_HighDosage - sd_Harm_LowDosage
sd_Purity_HighDosage - sd_Purity_LowDosage
# Hmmmm... I seem to be getting the OPPOSITE results as the authors. Is this an error in my code? Also, I couldn't get the standard deviation, is that an error in my code?
#Second analysis, the violin plot
## To create the violin plot, I will use the instructions I found here http://www.sthda.com/english/wiki/ggplot2-violin-plot-quick-start-guide-r-software-and-data-visualization
# Library
library(ggplot2)
View(d)
# Most basic violin chart
ggplot(d, aes(x=Purity_Violation, y=Rating, fill=name)) +
geom_violin()
# Library
library(ggplot2)
ggplot(d, aes(x=Purity_Violation, y=Rating, fill=name)) +
geom_violin()
# Most basic violin chart
ggplot(d, aes(x=Purity_Violation, y=Rating, fill=Purity_Violation)) +
geom_violin()
# Most basic violin chart
ggplot(d, aes(x=High_Dosage, y=Rating, fill=Purity_Violation)) +
geom_violin()
# Most basic violin chart
ggplot(d, aes(x=High_Dosage, y=Rating, fill=Purity_Violation)) +
geom_violin()
ggplot(d, aes(x=Purity_Violation, y=Rating, fill=High_Dosage)) +
geom_violin()
?lmer
library(lme4)
lmer
install.packages("lme4")
library(lme4)
lmer
?lmer
View(d)
lmer(Rating ~ Purity_Violation*High_Dosage, d)
lmer(Rating ~ Purity_Violation*High_Dosage + (Purity_Violation | High_Dosage), d)
####Load Relevant Libraries and Functions
library(foreign) # for reading spss formatted data
library(tidyverse)
####Import data, using the workaround Mike sent to the class in order to read Qualtrics data into R
#Also, how do I make sure that my data is anonymized??? I didn't really understand the class instructions for Mturk anonymization
filename <- "PilotAdata.csv"
headers = read_csv(filename, col_names = FALSE, n_max = 1)
df = read_csv(filename, skip = 3, col_names = FALSE)
colnames(df)= headers
#### Inspect data
colnames(df)
#### Data exclusion / filtering
data <- df %>%
filter(DistributionChannel == "anonymous") %>% # remove all the surveys that were unanswered and were just a "preview," leaving only the surveys that were "anonymous"
filter( (Att1_8 > 49) | (Att2_4 < 51) )  ## Include only rows where the person passed the first attention check, OR where they passed the second attention check.
# Is the above fix okay? Am I keeping all the data I intend to keep? --> I HAVE A PROBLEM HERE!!! It's also filtering out all the people who took Att2 but not Att1. How do I get it to keep the results when Att1_8 = NA?
#Also, I could maybe just get rid of the first row. I think the second filter does the same thing.
#Also, is there a way to keep track of how much data is excluded? I'm planning to go to office hours on Tuesday 12/3 and go through many of these questions.
head(data)
View(data)
head(data)
data <- df %>%
#    filter(DistributionChannel == "anonymous") %>% # remove all the surveys that were unanswered and were just a "preview," leaving only the surveys that were "anonymous"
filter( (Att1_8 > 49) | (Att2_4 < 51) )  ## Include only rows where the person passed the first attention check, OR where they passed the second attention check.
head(data)
#### Data exclusion / filtering
data <- df %>%
filter(DistributionChannel == "anonymous") %>% # remove all the surveys that were unanswered and were just a "preview," leaving only the surveys that were "anonymous"
filter( (Att1_8 > 49) | (Att2_4 < 51) )  ## Include only rows where the person passed the first attention check, OR where they passed the second attention check.
# Is the above fix okay? Am I keeping all the data I intend to keep? --> I HAVE A PROBLEM HERE!!! It's also filtering out all the people who took Att2 but not Att1. How do I get it to keep the results when Att1_8 = NA?
#Also, I could maybe just get rid of the first row. I think the second filter does the same thing.
#Also, is there a way to keep track of how much data is excluded? I'm planning to go to office hours on Tuesday 12/3 and go through many of these questions.
head(data)
####Load Relevant Libraries and Functions
library(foreign) # for reading spss formatted data
library(tidyverse)
####Import data, using the workaround Mike sent to the class in order to read Qualtrics data into R
#Also, how do I make sure that my data is anonymized??? I didn't really understand the class instructions for Mturk anonymization
filename <- "PilotAdata.csv"
headers = read_csv(filename, col_names = FALSE, n_max = 1)
df = read_csv(filename, skip = 3, col_names = FALSE)
colnames(df)= headers
#### Inspect data
colnames(df)
####Load Relevant Libraries and Functions
library(foreign) # for reading spss formatted data
library(tidyverse)
####Import data, using the workaround Mike sent to the class in order to read Qualtrics data into R
#Also, how do I make sure that my data is anonymized??? I didn't really understand the class instructions for Mturk anonymization
filename <- "PilotAdata.csv"
headers = read_csv(filename, col_names = FALSE, n_max = 1)
df = read_csv(filename, skip = 3, col_names = FALSE)
colnames(df)= headers
#### Inspect data
colnames(df)
#### Data exclusion / filtering
data <- df %>%
filter(DistributionChannel == "anonymous") %>% # remove all the surveys that were unanswered and were just a "preview," leaving only the surveys that were "anonymous"
filter( (Att1_8 > 49) | (Att2_4 < 51) )  ## Include only rows where the person passed the first attention check, OR where they passed the second attention check.
# Is the above fix okay? Am I keeping all the data I intend to keep? --> I HAVE A PROBLEM HERE!!! It's also filtering out all the people who took Att2 but not Att1. How do I get it to keep the results when Att1_8 = NA?
#Also, I could maybe just get rid of the first row. I think the second filter does the same thing.
#Also, is there a way to keep track of how much data is excluded? I'm planning to go to office hours on Tuesday 12/3 and go through many of these questions.
head(data)
View(data)
#### Data exclusion / filtering
data <- df %>%
# filter(DistributionChannel == "anonymous") %>% # remove all the surveys that were unanswered and were just a "preview," leaving only the surveys that were "anonymous"
filter( (Att1_8 > 49) | (Att2_4 < 51) )  ## Include only rows where the person passed the first attention check, OR where they passed the second attention check.
# Is the above fix okay? Am I keeping all the data I intend to keep? --> I HAVE A PROBLEM HERE!!! It's also filtering out all the people who took Att2 but not Att1. How do I get it to keep the results when Att1_8 = NA?
#Also, I could maybe just get rid of the first row. I think the second filter does the same thing.
#Also, is there a way to keep track of how much data is excluded? I'm planning to go to office hours on Tuesday 12/3 and go through many of these questions.
head(data)
View(data)
#### Data exclusion / filtering
data <- df %>%
filter( (Att1_8 > 49) | (Att2_4 < 51) )  ## Include only rows where the person passed the first attention check, OR where they passed the second attention check.
# Is the above fix okay? Am I keeping all the data I intend to keep? --> I HAVE A PROBLEM HERE!!! It's also filtering out all the people who took Att2 but not Att1. How do I get it to keep the results when Att1_8 = NA?
#Also, I could maybe just get rid of the first row. I think the second filter does the same thing.
#Also, is there a way to keep track of how much data is excluded? I'm planning to go to office hours on Tuesday 12/3 and go through many of these questions.
#### Data exclusion / filtering
data <- df %>%
filter( (Att1_8 > 49) | (Att2_4 < 51) )  ## Include only rows where the person passed the first attention check, OR where they passed the second attention check.
#Also, is there a way to keep track of how much data is excluded? I'm planning to go to office hours on Tuesday 12/3 and go through many of these questions.
#### Data exclusion / filtering
data <- df %>%
filter( (Att1_8 > 49) | (Att2_4 < 51) )  ## Include only rows where the person passed the first attention check, OR where they passed the second attention check.
#Also, is there a way to keep track of how much data is excluded? I'm planning to go to office hours on Tuesday 12/3 and go through many of these questions.
## Rottman also filtered out all the IP addresses that took both the pilot and the study --> do I need to do the same??
####Load Relevant Libraries and Functions
library(foreign) # for reading spss formatted data
library(tidyverse)
####Import data, using the workaround Mike sent to the class in order to read Qualtrics data into R
#Also, how do I make sure that my data is anonymized??? I didn't really understand the class instructions for Mturk anonymization
filename <- "PilotAdata.csv"
headers = read_csv(filename, col_names = FALSE, n_max = 1)
df = read_csv(filename, skip = 3, col_names = FALSE)
colnames(df)= headers
#### Inspect data
colnames(df)
####Load Relevant Libraries and Functions
library(foreign) # for reading spss formatted data
library(tidyverse)
####Import data, using the workaround Mike sent to the class in order to read Qualtrics data into R
#Also, how do I make sure that my data is anonymized??? I didn't really understand the class instructions for Mturk anonymization
filename <- "PilotAdata.csv"
headers = read_csv(filename, col_names = FALSE, n_max = 1)
df = read_csv(filename, skip = 3, col_names = FALSE)
colnames(df)= headers
#### Inspect data
colnames(df)
#### Data exclusion / filtering
data <- df %>%
filter( (Att1_8 > 49) | (Att2_4 < 51) )  ## Include only rows where the person passed the first attention check, OR where they passed the second attention check.
#Also, is there a way to keep track of how much data is excluded? I'm planning to go to office hours on Tuesday 12/3 and go through many of these questions.
## Rottman also filtered out all the IP addresses that took both the pilot and the study --> do I need to do the same??
#### Tidy my data
# I have a huge, super wide dataset. How do I make this tidier? What am I even trying to turn it into?
d <- data %>%
pivot_longer(cols = A1_10:Att2_4, names_to = "Prompt", values_to = "Rating") %>% # pivots into long form
select(c("Prompt", "Rating")) %>% # keeps only the columns I need
mutate(Purity_Violation = grepl("2", x = Prompt)) %>% # adds a column that says "TRUE" if the violation is a purity violation and "FALSE" if the violation is a harm violation
mutate(High_Dosage = grepl("'", x = Prompt)) # adds a column that says "TRUE" if the violation is the high-dosage version violation and "FALSE" if the violation is the low-dosage version violation
colnames(d)
# Now I only have four columns! Hurray! My data is nice and clean and long.
## Do I need to clean this up and label by subject?? I lost a lot of information when I tidied my data
# Do I need to add a dosage type (magnitude v frequence). ?? I think? although I think they don't end up using the dosage TYPE at all in the analysis.
# I should probably get rid of a lot of columns I don't need... do I need to do this?
#First analysis, difference of means
means <- d %>%
group_by(Purity_Violation, High_Dosage) %>%
summarize(meanWrongness = (mean(Rating, na.rm=T)))
sd <- d %>%
group_by(Purity_Violation, High_Dosage) %>%
summarize(meanWrongness = (sd(Rating, na.rm=T)))
means
sd
#First analysis, difference of means
means <- d %>%
group_by(Purity_Violation, High_Dosage) %>%
summarize(meanWrongness = (mean(Rating, na.rm=T)))
sd <- d %>%
group_by(Purity_Violation, High_Dosage) %>%
summarize(meanWrongness = (sd(Rating, na.rm=T)))
means
sd
# The difference between high-dosage  and low-dosage harm violations, and high-dosage and low-dosage purity violations
mean_Harm_LowDosage <- means[1,3]
mean_Harm_HighDosage <- means[2,3]
mean_Purity_LowDosage <- means[3,3]
mean_Purity_HighDosage <- means[4,3]
mean_Harm_HighDosage - mean_Harm_LowDosage
mean_Purity_HighDosage - mean_Purity_LowDosage
# Now I'll do the same analysis for standard deviations
sd_Harm_LowDosage <- sd[1,3]
sd_Harm_HighDosage <- sd[2,3]
sd_Purity_LowDosage <- sd[3,3]
sd_Purity_HighDosage <- sd[4,3]
# The difference in standard deviations between high-dosage  and low-dosage harm violations, and high-dosage and low-dosage purity violations
sd_Harm_HighDosage - sd_Harm_LowDosage
sd_Purity_HighDosage - sd_Purity_LowDosage
# Hmmmm... I seem to be getting the OPPOSITE results as the authors. Is this an error in my code? Also, I couldn't get the standard deviation, is that an error in my code?
diff_means_harms
# The difference between high-dosage  and low-dosage harm violations, and high-dosage and low-dosage purity violations
mean_Harm_LowDosage <- means[1,3]
mean_Harm_HighDosage <- means[2,3]
mean_Purity_LowDosage <- means[3,3]
mean_Purity_HighDosage <- means[4,3]
diff_means_harms <- mean_Harm_HighDosage - mean_Harm_LowDosage
diff_means_purity <- mean_Purity_HighDosage - mean_Purity_LowDosage
diff_means_harms
# Now I'll do the same analysis for standard deviations
sd_Harm_LowDosage <- sd[1,3]
sd_Harm_HighDosage <- sd[2,3]
sd_Purity_LowDosage <- sd[3,3]
sd_Purity_HighDosage <- sd[4,3]
# The difference in standard deviations between high-dosage  and low-dosage harm violations, and high-dosage and low-dosage purity violations
sd_Harm_HighDosage - sd_Harm_LowDosage
sd_Purity_HighDosage - sd_Purity_LowDosage
# Hmmmm... I seem to be getting the OPPOSITE results as the authors. Is this an error in my code? Also, I couldn't get the standard deviation, is that an error in my code?
# The difference between high-dosage  and low-dosage harm violations, and high-dosage and low-dosage purity violations
mean_Harm_LowDosage <- means[1,3]
mean_Harm_HighDosage <- means[2,3]
mean_Purity_LowDosage <- means[3,3]
mean_Purity_HighDosage <- means[4,3]
diff_means_harms <- mean_Harm_HighDosage - mean_Harm_LowDosage
diff_means_purity <- mean_Purity_HighDosage - mean_Purity_LowDosage
diff_means_harms
diff_means_purity
# Now I'll do the same analysis for standard deviations
sd_Harm_LowDosage <- sd[1,3]
sd_Harm_HighDosage <- sd[2,3]
sd_Purity_LowDosage <- sd[3,3]
sd_Purity_HighDosage <- sd[4,3]
# The difference in standard deviations between high-dosage  and low-dosage harm violations, and high-dosage and low-dosage purity violations
diff_sd_harms <- sd_Harm_HighDosage - sd_Harm_LowDosage
diff_sd_purity <- sd_Purity_HighDosage - sd_Purity_LowDosage
diff_sd_harms
diff_sd_purity
# Hmmmm... I seem to be getting the OPPOSITE results as the authors. Is this an error in my code? Also, I couldn't get the standard deviation, is that an error in my code?
View(means)
# The difference between high-dosage  and low-dosage harm violations, and high-dosage and low-dosage purity violations
View(means)
mean_Harm_LowDosage <- means[1,3]
mean_Harm_HighDosage <- means[2,3]
mean_Purity_LowDosage <- means[3,3]
mean_Purity_HighDosage <- means[4,3]
diff_means_harms <- mean_Harm_HighDosage - mean_Harm_LowDosage
diff_means_purity <- mean_Purity_HighDosage - mean_Purity_LowDosage
diff_means_harms
diff_means_purity
# Now I'll do the same analysis for standard deviations
sd_Harm_LowDosage <- sd[1,3]
sd_Harm_HighDosage <- sd[2,3]
sd_Purity_LowDosage <- sd[3,3]
sd_Purity_HighDosage <- sd[4,3]
# The difference in standard deviations between high-dosage  and low-dosage harm violations, and high-dosage and low-dosage purity violations
diff_sd_harms <- sd_Harm_HighDosage - sd_Harm_LowDosage
diff_sd_purity <- sd_Purity_HighDosage - sd_Purity_LowDosage
diff_sd_harms
diff_sd_purity
# Hmmmm... I seem to be getting the OPPOSITE results as the authors. Is this an error in my code? Also, I couldn't get the standard deviation, is that an error in my code?
#First analysis, difference of means
means <- d %>%
group_by(Purity_Violation, High_Dosage) %>%
summarize(meanWrongness = (mean(Rating, na.rm=T)))
sd <- d %>%
group_by(Purity_Violation, High_Dosage) %>%
summarize(meanWrongness = (sd(Rating, na.rm=T)))
means
sd
# The difference between high-dosage  and low-dosage harm violations, and high-dosage and low-dosage purity violations
mean_Harm_LowDosage <- means[1,3]
mean_Harm_HighDosage <- means[2,3]
mean_Purity_LowDosage <- means[3,3]
mean_Purity_HighDosage <- means[4,3]
diff_means_harms <- mean_Harm_HighDosage - mean_Harm_LowDosage
diff_means_purity <- mean_Purity_HighDosage - mean_Purity_LowDosage
diff_means_harms
diff_means_purity
# Now I'll do the same analysis for standard deviations
sd_Harm_LowDosage <- sd[1,3]
sd_Harm_HighDosage <- sd[2,3]
sd_Purity_LowDosage <- sd[3,3]
sd_Purity_HighDosage <- sd[4,3]
# The difference in standard deviations between high-dosage  and low-dosage harm violations, and high-dosage and low-dosage purity violations
diff_sd_harms <- sd_Harm_HighDosage - sd_Harm_LowDosage
diff_sd_purity <- sd_Purity_HighDosage - sd_Purity_LowDosage
diff_sd_harms
diff_sd_purity
# Hmmmm... I seem to be getting the OPPOSITE results as the authors. Is this an error in my code? Or have I just gathered too little data?
# Also, why are my standard deviations negative? That doesn't seem to make much sense....
#Second analysis, the violin plot
## To create the violin plot, I will use the instructions I found here http://www.sthda.com/english/wiki/ggplot2-violin-plot-quick-start-guide-r-software-and-data-visualization
# Library
library(ggplot2)
# Most basic violin chart
ggplot(d, aes(x=Purity_Violation, y=Rating, fill=High_Dosage)) +
geom_violin()
# Is this the right way to make four plots? Also, why does it look so weird?
# Third analysis, the linear regression
# For the linear regression, I will use the built-in function from R, lm.
# To do the statistical tricks described by Rottman (dropping a variable, adding random intercepts),
# I will have to talk to the TAs and figure out if those tricks are warranted on the data, and then how to do them.
library(lme4)
lmer(Rating ~ Purity_Violation*High_Dosage + (Purity_Violation | High_Dosage), d)
# lmer was the linear mixed model that Rottman used in his analysis. But I have no idea what the code is doing, and there seems to be an error too
