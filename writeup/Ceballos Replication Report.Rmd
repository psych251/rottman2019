---
title: "Replication of Study 1 from Rottman & Young (2019, Psychological Science)"
author: "Cristina Ceballos (cceballos@stanford.edu)"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    toc: yes
    toc_depth: 3
    toc_float:
      collapsed: false
---

<!-- Replication reports should all use this template to standardize reporting across projects.  These reports will be public supplementary materials that accompany the summary report(s) of the aggregate results. -->

## Introduction

The Rottman paper examines a question in moral psychology: how do people make moral judgments? Rottman thinks moral judgments are different across different domains. *Harm violations* (e.g. punching someone) are judged differently than *purity violations* (e.g. eating flesh from a dead person). Rottman proposes a "mere-trace hypothesis." According to Rottman's mere-trace hypothesis, "judgments of purity violations uniquely hinge on assessments of whether any amount of a transgresssion occurs and are only minimally affected by considerations of rate or quantity." Rottman at 1152. While the quantity or frequency of wrongdoing matters in *harm* violations (e.g. punching 50 people is worse than punching 1 person), quantity and frequency matter less in *purity* violations (e.g. eating flesh from 1 dead person is about as bad, morally speaking, as eating flesh from 50 dead people). According to Rottman's hypothesis, judgments of purity violations follow a "mere-trace" kind of reasoning, where even one small trace of a purity violation is enough to ruin the whole barrel. 

I chose Study 1 in Rottman's paper because of my interests in moral psychology. Rottman's question about moral judgments--is harm additive? are moral judgments different across different domains? how important are intentions?--have interesting implications for moral philosophy. In addition, Study 1 fell within the constraints of my (limited) technical skills and the class's research budget. Study 1 involved 200 participants on Mechanical Turk. Each participant completed a 16-item survey which asked them to rate the moral wrongness of an action (e.g. "How bad is it, on a scale from 0 to 100, when a person starves a goat?") Rottman's original paper provides the set of 32 questions used in the Mechanical Turk surveys.

## Links

Below is the link to my repository and the original paper by Rottman, titled "Specks of Dirt and Tons of Pain: Dosage Distinguishes Impurity From Harm."
https://github.com/psych251/rottman2019

The link to my Qualtrics survey is here:
https://stanforduniversity.qualtrics.com/jfe/form/SV_54k3tnFzYu5aXpr

The link to my preregistration on the OSF is here:
https://osf.io/n9q2w/?view_only=

I used .gitignore to make sure that the Pilot B data and the Final Data did not go up on Github, since it had potentially identifying details. I had already accidentally pushed it up onto Github, but I walked through a Git tutorial with a friend and he helped me remove Pilot B file from Github permanently. As an added precaution, I also manually deleted the columns that included the workers' IP Addresses and mTurk IDs.


## Methods

### Power Analysis

Rottman's original sample size was 177. His power analysis in the original paper relied on a complicated Monte Carlo simulation. The main effect that I am hoping to detect is the interaction between domain (harm vs. purity) and dosage type (low vs. high dosage) in a linear mixed model. Unfortunately, there is no ready-built package such as G*Power that does power analyses for linear mixed models. After a discussion with Mike, he advised me to do a simplified power analysis using Rottman's data.

Mike advised to take Rottman's data, and look at the harm violations only (ignoring purity violations). I should compare the low-dosage harm violations and the high-dosage harm violations, and do a t-test. The t-test would give me a t-value which I could convert into an effect size, and then I could use GPower software to calculate the sample size needed for a replication.


### My t-test and Power Analysis

I took Rottman's tidied, filtered, and cleaned data for Study 1. I created a CSV file called RottmanS1Data, which included only the data from Study 1. I created a group x, which has the high-dosage harm violations, and a group y, which has the low-dosage harm violations. Next, I will run my t-test on x and y.


```{r include=T}


library(foreign) # for reading spss formatted data
library(tidyverse)
library(dplyr)

Dosage.Tidy.S1 <- read.csv("RottmanS1Data.csv", header = TRUE)

# Use a filter to view ONLY the harm-related questions and exclude the purity-related questions 
Dosage.Tidy.S1_Harm <- Dosage.Tidy.S1  %>%
    filter(Domain == "Harm") # keep only the Harm prompts and exclude Purity

# Assign all the high-dosage harm violations to x
x <- Dosage.Tidy.S1_Harm %>%
     filter(Dose == "High")
  
# Assign all the low-dosage harm violations to y
y <- Dosage.Tidy.S1_Harm %>%
     filter(Dose == "Low")

# Run a t-test on x and y
  t.test(x$Wrong, y$Wrong)

```

In the above, I ran a t-test on Rottman's own data, to compare the low-dosage harm violations with the high-dosage harm violations. I got a t-value of 9.4355 and df = 1371.4.

Using these values, I found the effect size. I used an online calculator available at https://www.uccs.edu/lbecker/ . Into the calculator, I input t-value = 9.4355 and df = 1371.4 and got a Cohen's d = 0.5095805486569233.

Then I used the GPower software to calculate the power. I input "effect size = 0.5095805486569233" and "Tails: Two" and ran the GPower model for a "Correlation: point biserial model." According to GPower, I need a total sample size of 40 to get 95 percent power on a replication.



### Planned Sample

I followed Rottman's original study and selectd a target sample size of 200 total participants. Participants were recruited via Amazon's Mechanical Turk. Participation was limited to U.S.-based IP addresses and MTurk "Masters."


### Materials & Procedure

My replication study exactly followed the procedure of the Rottman study. The Rottman study described "Materials and Procedure" in one section, which I have copied into the text below.

"After providing consent to participate in the study, each participant was presented with 16 violations that varied by domain (harm vs. purity), dosage (low vs. high), and dosage type (magnitude vs. frequency). Participants saw two violations from each of the eight possible combinations of these variable levels (see Table 1). The presentation of these violations was counterbalanced across participants such that each participant saw either a low- or a high-dosage version of each violation and saw the opposite dosage from a corresponding violation in the other content domain. For example, participants who judged “A person throws a large rock at a farm animal” did not see “A person throws a small rock at a farm animal” but instead saw “A person eats a small amount of flesh from a dead person.” The two attention-check questions were also randomly presented within this sequence. After each moral violation was presented, participants were asked, “How morally wrong was this action?” and were prompted to respond on a slider scale from 0 (not at all) to 100 (extremely). 

Participants were then asked to provide basic demographic information and were debriefed.

The harm and purity violations were carefully matched for overall severity during stimulus construction, thus reducing the potential for confounding factors (Gray & Keeney, 2015), and their equivalence was confirmed in a pilot study (see the Supplemental Material available online). Because atypicality is a feature of the purity domain (i.e., impurity is often a function of the perceived unnaturalness of actions; Giner-Sorolla, Bosson, Caswell, & Hettinger, 2012; Graham, 2015), actions were not matched on this dimension." 


### Analysis Plan & Key Statistic

My analysis mimicked the Rottman analysis. 

First, I analyzed the difference in means between the high-dosage and low-dosage versions of the scenarios. Second, I created a violin plot, just as Rottman did for Fig. 1. As Rottman wrote in his study, "The difference in wrongness ratings between the high-dosage and low-dosage versions of the scenarios was substantially higher for the harm transgressions (mean difference = 14.605; SD = 20.395) than for the purity transgressions (mean difference = 4.185; SD = 16.060); the average difference between these differences was 10.419 (SD = 25.767), as can be seen in Figure 1."

Third, I created a linear mixed model to analyze the data. Rottman's analysis stated the following: "To more carefully examine the interaction between domain and dosage, we analyzed the data with a linear mixed model fitted using restricted maximum likelihood.... Including random intercepts for scenario and participant  provided the ability to generalize these findings to a broader range of stimuli and individuals ( Judd, Westfall, & Kenny, 2012), precluding arguments that the results are an artifact of the particular scenarios that were presented or the particular sample that was tested. The random effect of participant additionally accounted for the nonindependence of multiple judgments being made by each participant."

My key statistic was the *interaction between domain and dosage in the linear mixed model.* When I emailed Rottman and Liane, they agreed that this was the key statistic for their analysis. The Rottman paper stated, "Crucially, there was a significant interaction between domain and dosage, b = 9.599, SE = 1.821, p < .001, reflecting participants’ greater sensitivity to dosage for harm-based transgressions. Examining simple effects, we found that there was an effect of dosage both for harm transgressions, b = 13.999, SE = 1.288, p < .001, and for purity transgressions, b = 4.400, SE = 1.288, p = .001. Notably, however, the effect size of dosage for purity transgressions (d = 0.139) was less than one third of the effect size of dosage for harm transgressions (d = 0.441).

### Differences from Original Study

My study had a slightly different number of participants from Rottman's study. Rottman had a target of 200 participants, but his final sample had only 177 participants since many were excluded in attention checks. My study had a target of 200 participants, and I anticipated that some would also be excluded via attention checks.

### Exclusions & Methods Addendum (Post Data Collection)

Unfortunately, I was unable to collect the full 200 participant sample that I wanted. MTurk started running extremely slowly, even though I started my final data collection 9 days before the deadline. As a result, I only collected data from 162 participants, not the full 200 as I had planned. However, this should not cause any problems in the analysis because my sample size is still very large and well above the number I needed.

In addition, I excluded 5 participants because they failed the attention checks. I used the same attention checks as Rottman. Per Rottman, you fail the attention check if you rate "a person destroys the entire planet" below 49 on the moral wrongness scale, or if you rate "a person gives money to a charitable organization" above 51 on the moral wrongness scale. Each participant saw both attention checks, and I excluded participants who failed either attention check.

#### Differences from pre-data collection methods plan
  None.


## Results


### Data preparation

I created a survey on Qualtrics and linked that survey to Mechanical Turk. My survey had 16 questions, and each question has two dosages, so it is actually 32 questions total, plus the two attention checks, plus some demographic information. All the moral violation prompts were provided in the Rottman 2019 paper. Each participant was presented with 16 moral violations that varied by domain (harm vs. purity violation) and by dosage (low dosage vs. high dosage). The 16 questions and 2 attention checks were presented randomly. At the end of the survey, I collected demographic information from participants.

### Load Relevant Libraries 

Load Relevant Libraries and Functions

```{r include=T}

library(foreign) # for reading spss formatted data
library(tidyverse)
library(dplyr)

```

### Import Data 


Import data, using the workaround Mike sent to the class in order to read Qualtrics data into R. In the Qualtrics exporter, make sure to select "Use numeric values" and then also select "Remove line breaks" before hitting "export."

To further ensure mTurker anonymity, I manually deleted the columns "IPAddress" and "ResponseID" from my data.

```{r include=T}

filename <- "FINALdata.csv"
headers = read_csv(filename, col_names = FALSE, n_max = 1)
df = read_csv(filename, skip = 3, col_names = FALSE)
colnames(df)= headers

#### Inspect data

colnames(df)


```

#### Data exclusion / filtering

I filtered out the people who failed the attention checks. Per Rottman, you fail the attention check if you rate "a person destroys the entire planet" below 49 on the moral wrongness scale, or if you rate "a person gives money to a charitable organization" above 51 on the moral wrongness scale. Each participant saw both attention checks, and I excluded participants who failed either attention check.

I also filtered out the results from my pilots. Qualtrics included all the data in one file, so my data file includes ALL the survey results, but I want to exclude the survey results from the pilots. Therefore, I created filters for the StartDate and EndDate.


```{r include=T}
#### Data exclusion / filtering


# Select only the results collected after Dec 4, 2019, which is when I started my final data collection on MTurk.

df2 <- df[49:215,] # select rows 49 thru 215, which has all the data from after Dec 4, 2019. I found rows 49 thru 215 by manually looking at my dataframe df.

data <- df2 %>% 
  filter((Att1_8 > 49) & (Att2_4 < 51))  ## Include only rows where the person passed the first and second attention checks.

# To track how many people were excluded
excluded_data <- df2 %>% 
    filter(StartDate > "12/4/2019 23:37") %>%
    filter( (Att1_8 <= 49) | (Att2_4 >= 51) )

nrow(excluded_data) # counts the number of rows that have been excluded
nrow(data) # counts number of participants that were not excluded

```

This seems reasonable. Of my 166 participants, I kept 157 and excluded 5 who failed the attention checks.


### Tidy my data and make it longer

Note: I will use the "mTurkCode", not the IP Address or the Response ID, to identify the subjects. I deleted the IP Address and the Response ID from my dataset, just to be safe, and to better preserve mTurker anonymit. IP Address or Response ID is more easily de-identified, whereas mTurkCode preserves anonymity better. The mTurkCode is the randomly-generated payment code that Qualtrics generated for each survey participant.

```{r include=T}

d <- data %>%
  pivot_longer(cols = A1_10:Att2_4, names_to = "Prompt", values_to = "Rating") %>% # pivots into long form
  select(c("Prompt", "Rating", "mTurkCode")) %>% # keeps only the columns I need
  mutate(Purity_Violation = grepl("2", x = Prompt)) %>% # adds a column that says "TRUE" if the violation is a purity violation and "FALSE" if the violation is a harm violation 
  mutate(High_Dosage = grepl("'", x = Prompt)) %>% # adds a column that says "TRUE" if the violation is the high-dosage version violation and "FALSE" if the violation is the low-dosage version violation
  filter(Prompt != "Att1_8") %>% # remove the wrongness ratings for the first attention check
  filter(Prompt != "Att2_4") # remove the wrongess ratings for the second attention check

```

Now I only have five columns! Hurray! My data is nice and clean and long.


### Confirmatory analysis

The analyses as specified in the analysis plan.  

##### First analysis, difference of means

I'm trying to find the difference in the wrongness rating between the high-dosage and the low-dosage versions of the scenarios of the HARM transgressions. Then for the purity transgressions, I'll find the same thing. Then I will calculate the mean and the standard deviation of the difference in wrongness ratings, for both the purity and the harm.

First, I found the mean wrongness rating for each type of moral violation: harm low-dosage in Row 1, harm high-dosage in Row 2, purity low-dosage in Row 3, and purity high-dosage in Row 4.

```{r include=T}

means <- d %>%
  group_by(Purity_Violation, High_Dosage) %>%
  summarize(meanWrongness = (mean(Rating, na.rm=T)))

head(means)
```

The above chart illustrates the mean ratings of each kind of violation. Interestingly, we can see that most of the violations are rated fairly similarly, except the high-dosage harm violations, which have a big jump. This tends to support Rottman's hypothesis that we rate moral violations differently across different domains.

To calculate the difference of means and the standard deviation for harm and purity violations, I did the following:

```{r include=T}

# get condition means for each participant
mss <- d %>%
  group_by(mTurkCode, Purity_Violation, High_Dosage) %>%
  summarise(Rating = mean(Rating, na.rm=TRUE)) 

# get difference scores for each participant. 
diffs <- mss %>%
  summarise(diff = Rating[High_Dosage] - Rating[!High_Dosage], na.rm=TRUE)

# get mean and sd of those differences scores
diffs %>%
  group_by(Purity_Violation) %>%
  summarise(mean_diff = mean(diff, na.rm=TRUE), sd_diff = sd(diff, na.rm=TRUE))


```

So I found the same effect as Rottman! The difference in wrongness rating between high- and low-dosage violations was much higher for harm violations (about 11.5) than for purity violations (about 4.5). 

My numbers were not identical to Rottman's, but they were pretty close. Per Rottman, "The difference in wrongness ratings between the highdosage and low-dosage versions of the scenarios was substantially higher for the harm transgressions (mean difference = 14.605; SD = 20.395) than for the purity transgressions (mean difference = 4.185; SD = 16.060)." 

#### Second analysis, the violin plot

Next, I tried to re-create Rottman's Figure 1, a violin plot. 


```{r include=T}

# Load Library
library(ggplot2)

# Most basic violin chart
ggplot(mss, aes(x=Purity_Violation, y=Rating, fill=High_Dosage)) +
  geom_violin() +
  stat_summary(fun.data = "mean_cl_boot", 
               aes(group = High_Dosage), position=position_dodge(width = 1)) +
  ggtitle("Violin Plot, Replication of Fig. 1") +
  labs(x = "Purity Violation", y = "Wrongness Rating") 


```


The figure is not identical to Rottman's, but it shows the same main points. The high-dosage harm violations have the highest mean wrongness rating. The others hover around the high 60s to low 70s.


#### Third analysis, the linear regression

For the linear regression, I used the same function Rottman used, the lmer. This linear mixed allowed me to account for the fact that each participant provided 16 datapoints, rather than one participant per datapoint. This model also allowed me to account for the differences between the prompts.

```{r include=T}

library(lme4)
# library(lmerTest)

model <- lmer(Rating ~ Purity_Violation*High_Dosage + 
                (1 | mTurkCode) + 
                (1 | Prompt), d)

summary(model)

```

According to my linear mixed model, my key statistic, the interaction between domain and dosage, is about 6.8. Again, this is not identical to Rottman's, but it is pretty similar. Rottman had found an interaction term of 9.599. I am not sure why my model is telling me that the result is not significant. The Rottman paper had stated: "Crucially, there was a significant interaction between domain and dosage, b = 9.599, SE = 1.821, p < .001, reflecting participants’ greater sensitivity to dosage for harm-based transgressions. Examining simple effects, we found that there was an effect of dosage both for harm transgressions, b = 13.999, SE = 1.288, p < .001, and for purity transgressions, b = 4.400, SE = 1.288, p = .001. Notably, however, the effect size of dosage for purity transgressions (d = 0.139) was less than one third of the effect size of dosage for harm transgressions (d = 0.441).


Rottman also ran his model without the interaction terms, to simplify the main effects, so I will do the same
```{r include=T}
## Run the model without the interaction terms! Rottman also did this
model2 <- lmer(Rating ~ Purity_Violation + High_Dosage + 
                (1 | mTurkCode) + 
                (1 | Prompt), d)

summary(model2)

  
```


In this simplified linear model, I can see that domain (harm vs. purity) does not have a big effect (about 3.5), but dosage (high or low), does have a bigger effect (about 7.4). 

According to Rottman, this simplified linear model showed that: "Rerunning this model without the interaction term (to ensure more interpretable main effects) indicated that there was no overall effect of domain, b = 3.400, SE = 6.803, p = .625, thus revealing that the harm and purity transgressions were well matched for severity. Unsurprisingly, there was a clear effect of dosage, b = 9.199, SE = 0.915, p < .001, as high-dosage transgressions were judged to be more wrong than low-dosage transgressions."


### Exploratory analyses

I was curious to see which moral violations were most offensive, and which were rated less wrong. So, I pulled together a chart that ranked the wrongness of each violation.

Interesting. According to the chart, the very worst thing you can do is “purposely knock your sibling unconscious on many occasions.” Then the second-worst thing is to “starve a goat frequently.” But you’re barely immoral at all if you “kill two deer while hunting” -- this prompt had the lowest wrongness rating.

The results seem to make sense. The highest-rated violations were both high-dosage harm violations, which fits with the prior chart. And the lowest-rated violation was a low-dosage harm violation.


```{r include=T}

MostWrong <- d %>%
  group_by(Prompt, Purity_Violation) %>%
  summarize(meanWrongness = (mean(Rating, na.rm=T)))

print(MostWrong)


```



## Discussion

### Summary of Replication Attempt

Overall, my replication seems to have been successful: the difference in wrongness rating between the high-dosage and low-dosage violations was much higher for harm violations than for purity violations. My key statistic was the interaction between domain and dosage, where I found an interaction of about 6.8. While this was not identical to Rottman's interaction, which was b = 9.599, it was still fairly similar.


### Commentary

In the future, I will look at the original author's code and data much sooner! It was extremely helpful and I wish I had run it earlier in my analysis.

In addition, I will also reach out to the authors sooner. I was a bit intimidated to reach out to them, but once I did, they were incredibly kind and helpful! Their feedback was also very useful and I wish I had reached out sooner. 