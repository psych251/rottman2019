---
title: "Replication of Study 1 from Rottman & Young (2019, Psychological Science)"
author: "Cristina Ceballos (cceballos@stanford.edu)"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    toc: yes
    toc_depth: 3
    toc_float:
      collapsed: false
---

<!-- Replication reports should all use this template to standardize reporting across projects.  These reports will be public supplementary materials that accompany the summary report(s) of the aggregate results. -->

##Introduction

The Rottman paper examines a question in moral psychology: how do people make moral judgments? Rottman thinks moral judgments are different across different domains. *Harm violations* (e.g. punching someone) are judged differently than *purity violations* (e.g. eating flesh from a dead person). Rottman proposes a "mere-trace hypothesis." According to Rottman's mere-trace hypothesis, "judgments of purity violations uniquely hinge on assessments of whether any amount of a transgresssion occurs and are only minimally affected by considerations of rate or quantity." Rottman at 1152. While the quantity or frequency of wrongdoing matters in *harm* violations (e.g. punching 50 people is worse than punching 1 person), quantity and frequency matter less in *purity* violations (e.g. eating flesh from 1 dead person is about as bad, morally speaking, as eating flesh from 50 dead people). According to Rottman's hypothesis, judgments of purity violations follow a "mere-trace" kind of reasoning, where even one small trace of a purity violation is enough to ruin the whole barrel. 

I chose Study 1 in Rottman's paper because of my interests in moral psychology. Rottman's question about moral judgments--is harm additive? are moral judgments different across different domains? how important are intentions?--have interesting implications for moral philosophy. In addition, Study 1 falls within the constraints of my (limited) technical skills and the class's research budget. Study 1 involved 200 participants on Mechanical Turk. Each participant completed a 16-item survey which asked them to rate the moral wrongness of an action (e.g. "How bad is it, on a scale from 0 to 100, when a person starves a goat?") Rottman's original paper provides the total set of 32 questions used in the Mechanical Turk surveys. He also provides Supplemental Materials online that explain the equivalence between the harm violations and purity violations, which were matched for overall severity. 

With respect to my programming background, I have taken only one programming class, Stats 60. I believe this replication is feasible given my programming background and that it will push me to improve my skills.

Below is the link to my repository and the original paper by Rottman, titled "Specks of Dirt and Tons of Pain: Dosage Distinguishes Impurity From Harm."
https://github.com/psych251/rottman2019



##Methods

###Power Analysis

[TBC after we discuss in class*]

Original effect size, power analysis for samples to achieve 80%, 90%, 95% power to detect that effect size.  Considerations of feasibility for selecting planned sample size.

###Planned Sample

I will follow Rottman's original study and select a target sample size of 200 total participants. Participants will be recruited via Amazon's Mechanical Turk. I will limit particpants to U.S.-based IP addresses and MTurk "Masters."

Participants who fail attention checks will be excluded, but will still be paid. Participants who completed the pilot study will also be excluded, since they have already completed the task, but they will still be paid.

###Materials

My replication study exactly followed the procedure of the Rottman study. The Rottman study described "Materials and Procedure" in the same section, not in two separate sections, and the Rottman text is replicated below.

"After providing consent to participate in the study, each participant was presented with 16 violations that varied by domain (harm vs. purity), dosage (low vs. high), and dosage type (magnitude vs. frequency). Participants saw two violations from each of the eight possible combinations of these variable levels (see Table 1). The presentation of these violations was counterbalanced across participants such that each participant saw either a low- or a high-dosage version of each violation and saw the opposite dosage from a corresponding violation in the other content domain. For example, participants who judged “A person throws a large rock at a farm animal” did not see “A person throws a small rock at a farm animal” but instead saw “A person eats a small amount of flesh from a dead person.” The two attention-check questions were also randomly presented within this sequence. After each moral violation was presented, participants were asked, “How morally wrong was this action?” and were prompted to respond on a slider scale from 0 (not at all) to 100 (extremely). 

Participants were then asked to provide basic demographic information and were debriefed.

The harm and purity violations were carefully matched for overall severity during stimulus construction, thus reducing the potential for confounding factors (Gray & Keeney, 2015), and their equivalence was confirmed in a pilot study (see the Supplemental Material available online). Because atypicality is a feature of the purity domain (i.e., impurity is often a function of the perceived unnaturalness of actions; Giner-Sorolla, Bosson, Caswell, & Hettinger, 2012; Graham, 2015), actions were not matched on this dimension." 


###Procedure	

I precisely followed the procedure in Rottman's paper. Rottman's "Materials and Procedure" section is quted above.

###Analysis Plan

My analysis will replicate the Rottman analysis. 

First, I will analyze the difference in means between the high-dosage and low-dosage versions of the scenarios. I will create a violin plot, just as Rottman did for Fig. 1. As Rottman wrote in his study, "The difference in wrongness ratings between the high-dosage and low-dosage versions of the scenarios was substantially higher for the harm transgressions (mean difference = 14.605; SD = 20.395) than for the purity transgressions (mean difference = 4.185; SD = 16.060); the average difference between these differences was 10.419 (SD = 25.767), as can be seen in Figure 1."

Second, I will create a linear regression model to analyze the data. I am not certain if I will follow Rottman's exact analysis for the linear regression. Rottman created a "linear mixed model,"  not a straighforward linear regression, and Rottman's model also seems to include some fancy footwork with respect to variables (for example, Rottman dropped  dosage type as a variable, and he also included random intercepts). I am not sure if I will exactly replicate Rottman's model--I would first want to know a bit more about his choices, to ensure that the model is not just searching for a signal amidst all the noise. I will have to ask the instructors, who know more about statistics than I do, about Rottman's choices with respect to the linear regression model.

Rottman's analysis was the following: "To more carefully examine the interaction between domain and dosage, we analyzed the data with a linear mixed model fitted using restricted maximum likelihood. The model was specified to predict moral judgments from the fixed effects of domain (harm vs. purity) and dosage (low vs. high), the two-way interaction between these variables, and the random intercepts of scenario and participant. The model initially included dosage type as an additional factor, along with all interactions involving this factor. This analysis yielded a significant three-way interaction, b = 9.491, SE = 3.630, p = .009, driven by a decrease in wrongness for low-magnitude harms, which rendered the estimates of main effects and two-way interactions uninterpretable. Because we had no predictions about the effects of dosage type, this variable was dropped from the model. Including random intercepts for scenario and participant  provided the ability to generalize these findings to a broader range of stimuli and individuals ( Judd, Westfall, & Kenny, 2012), precluding arguments that the results are an artifact of the particular scenarios that were presented or the particular sample that was tested. The random effect of participant additionally accounted for the nonindependence of multiple judgments being made by each participant."


###Differences from Original Study

I will strive to exactly replicate Rottman's experiment. My linear regression analysis, however, may differ from Rottman's.

### Methods Addendum (Post Data Collection)

You can comment this section out prior to final report with data collection.

#### Actual Sample
  Sample size, demographics, data exclusions based on rules spelled out in analysis plan

#### Differences from pre-data collection methods plan
  Any differences from what was described as the original plan, or “none”.


##Results


### Data preparation

Data preparation following the analysis plan.
	
```{r include=T}
###Data Preparation

# I will create a survey on Qualtrics, and link that survey to Mechanical Turk. My survey has 16 questions, and each question has two dosages, so it is actually 32 questions total. All questions are provided in the Rottman 2019 paper. Each participant is presented with 16 moral violations, that vary by domain (harm vs. purity violation) and by . dosage (low vs. high or magnitude vs. frequency). I will use the "Randomizer" function in Qualtrics. To ensure that participants see the appropriate questions.

####Load Relevant Libraries and Functions

# The libraries I need are the useful, all-purpose libraries:

library(foreign) # for reading spss formatted data
library(tidyverse)

####Import data

data = read_csv("PilotAdata.csv", heade)

#### Look at data

View(data)
colnames(data)

#### Data exclusion / filtering

# For Pilot A, I have 6 actual survey results, and the rest are spam from when I was testing/building the survey.
# So I need to get rid of the ~25 entrieIs that are spam. The spam were all short, less than 75 seconds
# I'll also have to filter out the people who failed the attention checks.
# Per Rottman, you fail the attention check if you rate "a person destroys the entire planet" below 49 on the moral
# wrongness scale, or if you rate "a person gives money to a charitable organization" above 51 on moral wrongness.


data_filtered <- data %>% 
    filter(Att1_8 > 49)  %>%  # fail first attention check, "a person destroys the entire planet"
    filter(Att2_4 < 51)  %>%  # fail second attention check, "a person gives money to charity"
    filter(Duration..in.seconds. > 75) # filter out any quizzes that were completed in less than 75 seconds

# View(data_filtered)

#For some reason the above code is not working.... I'll have to go to office hours


#### Prepare data for analysis - create columns etc.
  
  
```

### Confirmatory analysis

The analyses as specified in the analysis plan.  

```{r include=T}

#First analysis, difference of means
# I'm trying to find the difference in the wrongness rating between the high-dosage and the low-dosage versions of the scenarios of the HARM transgressions. Then for the purity transgressions, I'll find the same thing.

# First I'll select only the harm transgressions, which are the A1, B1, C1, etc.

# harm_data_filtered <- data_filtered %>% 
  # select(A1, A1., B1, B1., C1, C1.   ) # ...etc. But it's making my column names weird for some reason, so I'll ask for help
  
# Now I'll get the difference in wrongness between the high-dosage and low-dosage versions.
# I think I'll need a group_by and a summarize, but since none of my code is working, I'm not sure!!!


# Then do the same thing for the purity violations

```


```{r include=T}

#Second analysis, the violin plot

## To create the violin plot, I will use the instructions I found here http://www.sthda.com/english/wiki/ggplot2-violin-plot-quick-start-guide-r-software-and-data-visualization 

# Basic violin plot
# p <- ggplot(ToothGrowth, aes(x=dose, y=len)) + 
  # geom_violin()
# p

# Rotate the violin plot
# p + coord_flip()
# Set trim argument to FALSE
# ggplot(ToothGrowth, aes(x=dose, y=len)) + 
  # geom_violin(trim=FALSE)

# None of my code is working so I'll have to go to office hours

```


```{r include=T}


# Third analysis, the linear regression

# For the linear regression, I will use the built-in function from R, lm.
# To do the statistical tricks described by Rottman (dropping a variable, adding random intercepts), 
# I will have to talk to the TAs and figure out if those tricks are warranted on the data, and then how to do them.

# None of my code is working so I will go to office hours 
  
```



*Side-by-side graph with original graph is ideal here*

###Exploratory analyses

Any follow-up analyses desired (not required).  

## Discussion

### Summary of Replication Attempt

Open the discussion section with a paragraph summarizing the primary result from the confirmatory analysis and the assessment of whether it replicated, partially replicated, or failed to replicate the original result.  

### Commentary

Add open-ended commentary (if any) reflecting (a) insights from follow-up exploratory analysis, (b) assessment of the meaning of the replication (or not) - e.g., for a failure to replicate, are the differences between original and present study ones that definitely, plausibly, or are unlikely to have been moderators of the result, and (c) discussion of any objections or challenges raised by the current and original authors about the replication attempt.  None of these need to be long.
